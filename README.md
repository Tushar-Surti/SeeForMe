# ğŸ‘ï¸ SeeForMe

> **Empowering independence for visually impaired individuals through real-time, multilingual scene understanding with audio feedback - now 100% offline!**

---

## ğŸŒŸ Overview

Visually impaired individuals often struggle to identify objects and navigate their surroundings independently.
While existing solutions exist, they are often:

* ğŸŒ Limited to **English only**
* âš ï¸ Difficult to operate without visual interaction
* ğŸš« Lacking **support for Indian languages**
* âŒ Not optimized for **simple, accessible controls**
* ğŸ”Œ **Require internet connectivity**
* ğŸ”’ **Privacy concerns** with cloud-based processing

**SeeForMe** bridges this gap by providing:

âœ… Real-time **object & scene recognition** using on-device AI
âœ… **Audio feedback** in multiple Indian languages
âœ… **Accessible navigation** via simple controls (like volume buttons)
âœ… A **user-friendly mobile app** designed with inclusivity at its core
âœ… **100% offline operation** - no internet required
âœ… **Complete privacy** - all processing happens on your device

---

## ğŸ¯ Key Features

* ğŸ” **Object Detection & Scene Understanding** â€“ AI-powered recognition using YOLO (80+ object classes)
* ğŸ§  **Spatial Awareness** â€“ Understands object positions (left/right/center, near/far) and relationships
* ğŸ—£ï¸ **Multilingual Audio Output** â€“ Support for 10 Indian languages + English
* ğŸ§ **Natural Language Descriptions** â€“ Phi-3 LLM generates clear, spoken descriptions
* ğŸ›ï¸ **Simple Controls** â€“ Operate via volume buttons for hands-free accessibility
* ğŸ“± **Mobile-first Design** â€“ Optimized for Android devices
* ğŸ”’ **Privacy-First** â€“ All AI processing happens on-device, no data leaves your phone
* âœˆï¸ **Works Offline** â€“ No internet connection required

---

## ğŸ—ï¸ Architecture

### Offline Processing Pipeline

```
Camera Frame
    â†“
YOLO Object Detection (TensorFlow Lite)
    â†“
Spatial Scene Analysis
    â†“
Phi-3 Mini LLM (Local Inference)
    â†“
Offline Translation (if needed)
    â†“
Text-to-Speech (Multi-language)
```

**All processing happens on your device!**

---

## ğŸ› ï¸ Tech Stack

* **Computer Vision**: YOLOv5s FP16 (TensorFlow Lite)
* **Natural Language**: Phi-3 Mini (Quantized for mobile)
* **Languages**: Dart/Flutter for mobile app
* **Text-to-Speech (TTS)**: Native platform TTS engines
* **ML Framework**: TensorFlow Lite
* **Platform**: Android (iOS support available via Flutter)
* **Translation**: Offline dictionary-based translation

---

## ğŸŒ Supported Languages

* ğŸ‡¬ğŸ‡§ English (en)
* ğŸ‡®ğŸ‡³ Hindi (hi)
* ğŸ‡®ğŸ‡³ Gujarati (gu)
* ğŸ‡®ğŸ‡³ Bengali (bn)
* ğŸ‡®ğŸ‡³ Telugu (te)
* ğŸ‡®ğŸ‡³ Tamil (ta)
* ğŸ‡®ğŸ‡³ Marathi (mr)
* ğŸ‡®ğŸ‡³ Kannada (kn)
* ğŸ‡®ğŸ‡³ Malayalam (ml)
* ğŸ‡®ğŸ‡³ Punjabi (pa)

---

## ğŸ“¦ Installation & Setup

### Prerequisites
- Flutter SDK (latest stable version)
- Android Studio / Xcode (for mobile development)
- TensorFlow Lite models (see setup instructions below)

### Steps

1. **Clone the repository:**
   ```bash
   git clone https://github.com/yourusername/SeeForMe.git
   cd SeeForMe
   ```

2. **Install dependencies:**
   ```bash
   flutter pub get
   ```

3. **Download AI models:**
   - See `assets/models/README.md` for detailed model download instructions
   - Required models:
     - `yolov5s-fp16.tflite` (~15-20 MB)
    - `phi3-mini.gguf` (~50-200 MB)
   - Place models in `assets/models/` directory

4. **Run the app:**
   ```bash
   flutter run
   ```

5. **Build release APK:**
   ```bash
   flutter build apk --release
   ```

For detailed setup and troubleshooting, see [OFFLINE_MIGRATION.md](OFFLINE_MIGRATION.md)

---

## ğŸ“¸ App Screenshots

<!-- | Home Screen                      | Object Detection                      | Scene Description                 | Settings                             |
| -------------------------------- | ------------------------------------- | --------------------------------- | ------------------------------------ |
| ![Home](screenshots/screen1.png) | ![Detection](screenshots/screen2.png) | ![Scene](screenshots/screen3.png) | ![Settings](screenshots/screen4.png) | -->
<p align="center">
  <img src="screen1.png" width="100%" alt="Home Screen"/>
</p>

<p align="center">
  <img src="screen2.png" width="100%" alt="Object Detection"/>
</p>

<p align="center">
  <img src="screen3.png" width="100%" alt="Scene Description"/>
</p>
---

## ğŸ› ï¸ Tech Stack

<!-- * **Computer Vision**: YOLOv8 / MobileNet (optimized for edge devices)
* **Languages**: Python, Java/Kotlin (for mobile integration)
* **Text-to-Speech (TTS)**: Google TTS / Open-source Indian language TTS engines
* **Frameworks**: TensorFlow Lite / ONNX Runtime
* **Platform**: Android (planned iOS support later) -->

---

## ğŸ§‘â€ğŸ¤â€ğŸ§‘ Team & Credits

Developed with â¤ï¸ to make technology more **inclusive** and **accessible**.

---

<!-- ## ğŸ“œ License

This project is licensed under the **MIT License** â€“ feel free to use and improve it.

--- -->

âœ¨ *â€œSee the world, your way.â€*

---

